{
    "contents" : "###################################################\n# Examples on how to use these functions\n##################################################\n\nrm(list=ls())\n\nsource(\"scripts/SummaryFunctions.R\")\n\n# load data\nmydocs <- grep(\"Wikipedia\", dir(\"data/\"), value=TRUE)\n\nmydocs <- sapply(mydocs, function(DOC){\n    result <- scan(paste(\"data\", DOC, sep=\"/\"), sep=\"\\n\", what=\"character\")\n    \n    result <- paste(result, collapse=\" \")\n    \n    return(result)\n})\n\n# parse sentences\nmysentences <- lapply(mydocs, function(doc){\n    # extract sentences\n    doc <- ParseSentences(doc = doc)\n    \n    return(doc)\n})\n\n# get dtms\nmydtms <- lapply(mysentences, function(doc){\n    # get dtm of sentences\n    dtm <- MakeSentenceDtm(doc = doc, stem=FALSE, min.ngram=1, max.ngram=1)\n    return(dtm)\n})\n\n##########################################\n# Get some keywords from each document\n##########################################\n\nmykeywords <- lapply(mydtms, function(x){\n    ExtractKeywords(dtm=x, M=7)\n})\n\n##########################################\n# Summarize based on \"raw\" word counts\n##########################################\nsummaries.raw <- mapply(function(dtm, doc){\n    # keep only sentences that have at least 5 words and less than 21\n    dtm <- dtm[ rowSums(dtm) %in% 5:20, ] \n    \n    # get adjacency matrix\n    g <- MakeSentenceAdjmat(dtm = dtm, method=\"raw\")\n    \n    # top N sentences based on eigenvector centrality\n    top.n <- SentenceEigenRank(igraph.object = g, sentences = doc, N = 5)\n    \n    # paste together for final result and output\n    summary <- paste(top.n, collapse=\" \")\n    \n    return(summary)\n}, dtm=mydtms, doc=mysentences)\n\n##########################################\n# Summarize based on cosine similarity\n##########################################\nsummaries.csim <- mapply(function(dtm, doc){\n    # keep only sentences that have at least 5 words and less than 21\n    dtm <- dtm[ rowSums(dtm) %in% 5:20, ] \n    \n    # get adjacency matrix\n    g <- MakeSentenceAdjmat(dtm = dtm, method=\"cosine\")\n    \n    # top N sentences based on eigenvector centrality\n    top.n <- SentenceEigenRank(igraph.object = g, sentences = doc, N = 5)\n    \n    # paste together for final result and output\n    summary <- paste(top.n, collapse=\" \")\n    \n    return(summary)\n}, dtm=mydtms, doc=mysentences)\n\n##########################################\n# Summarize based on keywords\n##########################################\nsummaries.key <- mapply(function(dtm, doc){\n    # keep only sentences that have at least 5 words and less than 21\n    dtm <- dtm[ rowSums(dtm) %in% 5:20, ] \n    \n    # get adjacency matrix\n    g <- MakeSentenceAdjmat(dtm = dtm, method=\"keyword\")\n    \n    # top N sentences based on eigenvector centrality\n    top.n <- SentenceEigenRank(igraph.object = g, sentences = doc, N = 5)\n    \n    # paste together for final result and output\n    summary <- paste(top.n, collapse=\" \")\n    \n    return(summary)\n}, dtm=mydtms, doc=mysentences)\n\n##########################################\n# Write output\n##########################################\nwrite.table(summaries.raw, \"output/summaries.raw.txt\", sep=\"\\t\", row.names=T, col.names=F)\nwrite.table(summaries.raw, \"output/summaries.csim.txt\", sep=\"\\t\", row.names=T, col.names=F)\nwrite.table(summaries.raw, \"output/summaries.key.txt\", sep=\"\\t\", row.names=T, col.names=F)\n\n\n\n",
    "created" : 1403581847653.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2697058789",
    "id" : "5C3E0F64",
    "lastKnownWriteTime" : 1403581870,
    "path" : "~/Documents/DocSummarizer/scripts/ExampleSummary.R",
    "project_path" : "scripts/ExampleSummary.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}